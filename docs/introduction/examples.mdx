---
title: 'Examples'
description: 'Quick snippets showing some features of Enochian'
---

## Backend Swapping

If you want to do mixture of agents or something along those lines, you can dynamically swap between backends.

```typescript
import ProgramState, { OpenAIBackend } from 'enochian-js';

const s = new ProgramState();

await s.setModel('http://localhost:30000');
await s
    .add(s.system`You are a helpful assistant.`)
    .add(s.user`Tell me a joke`)
    .add(s.assistant`${s.gen('answer1')}`);

s.setBackend(
    new OpenAIBackend({ apiKey: process.env.OPENAI_KEY }),
).setModel({ modelName: 'gpt-4o' });

await s
    .add(s.user`Tell me a better one`)
    .add(s.assistant`No problem! ${s.gen('answer2')}`);
console.log(s.get('answer1'), '\n------\n', s.get('answer2'));
```

## Choices

Force the LLM to pick between multiple choices. It's implemented by implemented by computing the [token-length normalized log probabilities](https://blog.eleuther.ai/multiple-choice-normalization/) of all choices and selecting the one with the highest probability (full credit goes to the sglang folks for this).

```typescript
import ProgramState from 'enochian-js';

const s = new ProgramState();

await s.setModel('http://localhost:30000');
await s
    .add(s.system`You are an animal.`)
    .add(s.user`What are you?`)
    .add(
        s.assistant`I am a ${s.gen('answer', { choices: ['hippopotamus', 'giraffe'] })}`,
    );

console.log(s.get('answer'));
```

## Forking

Sometimes, you can reach a state in your program which is parallelizable.

```typescript
import ProgramState from 'enochian-js';

const s = new ProgramState();
await s.setModel('http://localhost:30000');

s.add(s.system`You are a helpful assistant.`)
    .add(s.user`How can I stay healthy?`)
    .add(s.assistant`Here are two tips for staying healthy:
        1. Balanced Diet. 2. Regular Exercise.\n\n`);

const forks = s.fork(2);
await Promise.all(
    forks.map((f, i) =>
        f
            .add(
                f.user`Now, expand tip ${(i + 1).toString()} into a paragraph.`,
            )
            .add(
                f.assistant`${f.gen('detailed_tip', { sampling_params: { max_new_tokens: 256 } })}`,
            ),
    ),
);

await s
    .add(s.user`Please expand.`)
    .add(s.assistant`Tip 1: ${forks[0]?.get('detailed_tip') ?? ''}
        Tip 2: ${forks[1]?.get('detailed_tip') ?? ''}
        In summary, ${s.gen('summary')}`);

console.log(s.get('summary'));
```

In this case, the expanded tips for 1 and 2 don't depend on each other, so we can generate both at the same time using the `fork` function.
Then, we can join them back into the parent `ProgramState` and continue generating from there.

## Streaming

Enochian of course also supports streaming, so you can use it for a chat application frontend.

```typescript
import ProgramState from 'enochian-js';

const s = new ProgramState();

await s.setModel('http://localhost:30000');
const gen = s
    .add(s.system`You are a helpful assistant.`)
    .add(s.user`Tell me a joke`)
    .add(s.assistant`${s.gen('answer1', { stream: true })}`);
for await (const chunk of gen) {
    console.log(chunk.content);
}
console.log(s.get('answer1'), s.getMetaInfo('answer1'));
```

## Constrained decoding

For structured outputs, you can pass in either a regex, a [JsonSchema](https://json-schema.org/), or a
(zod)[https://zod.dev/] schema inside [`SamplingParams`](/api-reference/request-types#SamplingParams).
Zod types are the preferred way since it allows for type safety in the [`.get`](/api-reference/program-state#get).

```typescript
import ProgramState from 'enochian-js'
import { z } from 'zod';

const schema = z.object({
    id: z.string().uuid(),
    name: z.string().min(2).max(50),
    age: z.number().int().min(0).max(120),
    email: z.string().email(),
    tags: z.array(z.string()).min(1).max(5),
    role: z.enum(['admin', 'user', 'guest']),
    settings: z
        .object({
            theme: z.enum(['light', 'dark']),
            notifications: z.boolean(),
        })
        .optional(),
    // You can't use z.date() since the LLM will generate a datestring, not a Date
    joinedAt: z.string().date(),
});

const s = new ProgramState();

await s.setModel('http://localhost:30000');
await s
    .add(s.user`Describe a google employee's profile in json format`)
    .add(
        s.assistant`${s.gen('answer', { sampling_params: { zod_schema: schema } })}`,
    );
const profile = s.get('answer', schema);
console.log(profile);
```

<Note>If you know how to make the return type of `.get` automatically inferred by the schema passed into
`.gen`, please let me know!</Note>
